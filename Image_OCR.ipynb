{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical Character Recognition\n",
    "\n",
    "[HMI Text OCR](https://apmonitor.com/dde/index.php/Main/TextOCR) in the [Data-Driven Engineering](http://apmonitor.com/dde) online course.\n",
    "\n",
    "<img align=left width=500px src='https://apmonitor.com/dde/uploads/Main/image_ocr.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recognizing text information from Human Machine Interface (HMI) screens is an important interface with legacy or proprietary systems to digitize values. These systems might lack open data communication capabilities such as Modbus, MQTT, OPC UA, Websockets, or . OCR recognition of the text on the screen may be important for one or multiple of these reasons:\n",
    "\n",
    "- **Data Accessibility:** Legacy and proprietary systems may not provide easy access to the data in digital formats. Extracting text information from HMI screens allows for digitization, making it accessible for further analysis and integration with modern systems.\n",
    "- **Automation:** Manual data entry from HMI screens is time-consuming and error-prone. Automating the process of extracting text information enables greater efficiency and accuracy in data collection and processing.\n",
    "- **Integration:** Digitized data from HMI screens can be seamlessly integrated into modern software solutions, enabling real-time monitoring, analysis, and reporting, which is vital for decision-making and system optimization.\n",
    "- **Historical Data Preservation:** For legacy systems, digitizing HMI screen data is essential for preserving historical records. This helps organizations maintain a comprehensive historical database for compliance, troubleshooting, and maintenance purposes.\n",
    "- **Remote Monitoring:** Digitized data allows for remote monitoring of systems, which is particularly important in industries where physical access to the equipment is limited or risky.\n",
    "\n",
    "Python code recognizes characters on the screen from an image (e.g. PNG) or video frame (e.g. MP4) using the easyocr library. easyocr is a Python library that simplifies Optical Character Recognition (OCR) tasks. Install easyocr using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install easyocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example code snippet to perform text recognition from an image file from a Falcon F5 locator screen that measures ground depth.\n",
    "\n",
    "<img align=left width=300px src='https://apmonitor.com/dde/uploads/Main/falconf5.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import urllib.request\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download image\n",
    "file = 'falconf5.png'\n",
    "url = 'http://apmonitor.com/dde/uploads/Main/'+file\n",
    "urllib.request.urlretrieve(url,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Reader and Extract Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PaddleOCR reader\n",
    "ocr = easyocr.Reader(['en'])\n",
    "\n",
    "# Read image\n",
    "img = np.array(Image.open(file))\n",
    "\n",
    "# Extract values\n",
    "result = ocr.readtext(img)\n",
    "for r in result:\n",
    "    print(f'{r[1]} loc: {r[0]} conf: {np.round(r[2],2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=left width=500px src='https://apmonitor.com/dde/uploads/Main/activity.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity: Digitize Values from Video\n",
    "\n",
    "Extend the single image OCR to a video file. Record the series of numbers on the screen in a single CSV (Comma Separated Value) file with a video frame identifier. Create a plot of the depth as the locator repeatedly scans to increase accuracy.\n",
    "\n",
    "```python\n",
    "video = 'http://apmonitor.com/dde/uploads/Main/dci.mp4'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "import cv2\n",
    "import easyocr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download image\n",
    "file = 'dci.mp4'\n",
    "url = 'http://apmonitor.com/dde/uploads/Main/'+file\n",
    "urllib.request.urlretrieve(url,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Frames of Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the reader\n",
    "ocr = easyocr.Reader(['en'])\n",
    "\n",
    "# Read video file with OpenCV\n",
    "cap = cv2.VideoCapture(file)\n",
    "\n",
    "# results\n",
    "csv_file = file+'.csv'\n",
    "\n",
    "# Check if the video file opened\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Loop through each frame in the video\n",
    "ic=0\n",
    "while True:\n",
    "    print(ic)\n",
    "    ret, frame = cap.read()\n",
    "    # Break the loop when we reach the end of the video\n",
    "    if not ret:\n",
    "        break\n",
    "    # Convert BGR to RGB\n",
    "    img = np.array(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    # Identify text\n",
    "    result = ocr.readtext(img)\n",
    "\n",
    "    # Write header\n",
    "    if ic==0:\n",
    "        fid = open(csv_file,'w')\n",
    "        # write header\n",
    "        for i in range(len(result)):\n",
    "            fid.write(f'data{i},')\n",
    "        fid.write('frame\\n')\n",
    "        fid.close()\n",
    "\n",
    "    # write data to file\n",
    "    fid = open(csv_file,'a')        \n",
    "    for r in result:\n",
    "        fid.write(f'{r[1]},')\n",
    "    fid.write(f'{ic}\\n')\n",
    "    fid.close()\n",
    "\n",
    "    # increment frame counter\n",
    "    ic += 1\n",
    "\n",
    "# Release the video capture object and close file\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "dci = pd.read_csv(csv_file)\n",
    "# rename columns\n",
    "dci.columns = ['Read','rm','Depth (ft)','Signal','Frame']\n",
    "# remove second column\n",
    "del dci['rm']\n",
    "# set Frame as index\n",
    "dci.set_index('Frame',drop=True)\n",
    "# convert ft' in\" to meters\n",
    "dci['Depth (m)'] = (dci['Depth (ft)'].str.extract(\"(\\d*)'(\\d*)\\\"\")\n",
    "                    .apply(pd.to_numeric, errors='coerce')\n",
    "                    .mul([0.3048, 0.0254]).sum(axis=1)\n",
    "                   )\n",
    "# filter out bad data\n",
    "dci = dci[dci['Depth (m)']>2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create plot of depth\n",
    "dci['Depth (m)'].plot(figsize=(6,3))\n",
    "plt.xlabel('Frame'); plt.ylabel('Depth (m)')\n",
    "plt.tight_layout(); plt.savefig('results.png',dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

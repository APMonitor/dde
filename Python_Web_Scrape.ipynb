{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping with Python\n",
    "\n",
    "[Web Scrape with Python](https://www.apmonitor.com/dde/index.php/Main/WebScraping) in the [Data-Driven Engineering](http://apmonitor.com/dde) online course.\n",
    "\n",
    "<img align=left width=500px src='https://apmonitor.com/dde/uploads/Main/python_web_scrape.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internet data is a rich source of information. Much of the online information is designed for web-browsers and viewed by humans. Web scraping is data retrieval and curation of online information by a computer program. Scraping automates tedious manual retrieval of information and can be used to watch for updates. The exercises in this section demonstrate how to retrieve data from a website such as an image and a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“·  Download Image\n",
    "\n",
    "Download `python_web_scrape.png` from [Web Scraping with Python](http://apmonitor.com/dde/index.php/Main/WebScraping) using the `urllib` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# download image\n",
    "img = 'python_web_scrape.png'\n",
    "url = 'http://apmonitor.com/dde/uploads/Main/'+img\n",
    "urllib.request.urlretrieve(url, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages for image manipulation and computer vision include `Pillow` (Python Imaging Library), `Scikit-image`, `Matplotlib` (uses Pillow functions), and `OpenCV`. OpenCV is the most capable computer vision package and is supported in many development environments. Display the image with `Matplotlib`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "im = plt.imread(img)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¢  Read Table with Pandas\n",
    "\n",
    "The [Pandas Time-Series](https://www.apmonitor.com/dde/index.php/Main/PandasTimeSeries) exercise has a sample exercise that demonstrates how to read a [text file](https://apmonitor.com/dde/uploads/Main/tclab.txt) either from a local directory or from a URL address. However, suppose data is online as an HTML table as shown in [Web Scrape with Python](https://www.apmonitor.com/dde/index.php/Main/WebScraping).\n",
    "\n",
    "<html>\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>time</th>\n",
    "      <th>Q1</th>\n",
    "      <th>Q2</th>\n",
    "      <th>T1</th>\n",
    "      <th>T2</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0.0</th>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>20.9495</td>\n",
    "      <td>20.9495</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>5.0</th>\n",
    "      <td>0.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>20.9495</td>\n",
    "      <td>20.9495</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>10.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>20.9495</td>\n",
    "      <td>20.9495</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>15.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>21.5941</td>\n",
    "      <td>20.9495</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>20.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>22.2387</td>\n",
    "      <td>20.9495</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>25.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>22.8833</td>\n",
    "      <td>20.9495</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>30.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>23.8502</td>\n",
    "      <td>20.9495</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>35.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>25.1394</td>\n",
    "      <td>21.2718</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>40.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>26.1063</td>\n",
    "      <td>21.2718</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>45.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>27.0732</td>\n",
    "      <td>21.5941</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>50.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>28.3624</td>\n",
    "      <td>21.5941</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>55.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>29.3293</td>\n",
    "      <td>21.5941</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>60.0</th>\n",
    "      <td>70.0</td>\n",
    "      <td>0.0</td>\n",
    "      <td>30.6185</td>\n",
    "      <td>21.9164</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the table into Python with Pandas `read_html()` function. This function returns any tables on a webpage as a list. Use `[0]` to retrieve the first table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'http://apmonitor.com/dde/index.php/Main/WebScraping'\n",
    "data = pd.read_html(url)[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table can be modified as a `DataFrame`, such as setting the index as time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.set_index('time',inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”¢  Read Table with requests\n",
    "\n",
    "Many websites are designed to block program (bot) access to avoid Distributed Denial of Service (DDoS) attacks that can overwhelm a web service. Before sending many requests, it is important to check with the website owner to not overload the service. Read the table with `requests` to include a header that emulates a browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# look like a browser\n",
    "header = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64) \"+\n",
    "                \"AppleWebKit/537.36 (KHTML, like Gecko) \"+\n",
    "                \"Chrome/50.0.2661.75 Safari/537.36\",\n",
    "  \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "r = requests.get(url, headers=header)\n",
    "data = pd.read_html(r.text)[0]\n",
    "data.set_index('time',inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ¥£ Beautiful Soup\n",
    "\n",
    "[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) is a Python package for extracting (scraping) information from web pages. It uses an HTML or XML parser and functions for iterating, searching, and modifying the parse tree. First, get the html source from a webpage such as this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://apmonitor.com/dde/index.php/Main/WebScraping?action=print'\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `page.content` contains the html source if `page_status_code` starts with a `2` such as 200 (downloaded successfully). A `4` or `5` indicates an error. BeautifulSoup parses HTML or XML files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions such as `print(soup.prettify())` can be used to view the structured output or the page title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the links are extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in soup.find_all('a'):\n",
    "    print('Link Text: {}'.format(link.text))\n",
    "    print('href: {}'.format(link.get('href')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pandas` uses `BeautifulSoup` to extract tables from webpages. Data scraping is particularly useful for getting information from webpages that are updated with new information such as weather, stock data, and customer reviews. More advanced web scraping packages are `MechanicalSoup`, `Scrapy` and `Selenium`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Activity\n",
    "\n",
    "Practice web scraping to retrieve data from another website of interest that contains a table. Organize the content into a DataFrame and export the DataFrame to a CSV file. Below is an example of retrieval from the [Wikipedia article on Data Tables](https://en.wikipedia.org/wiki/Table_(information)) where the data table is saved as `test.csv`. Change the `url`, use `requests` with a browser header if necessary, and export the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'https://en.wikipedia.org/wiki/Table_(information)'\n",
    "req = requests.get(url)'\n",
    "data = pd.read_html(req.content)[0]'\n",
    "data.to_csv('test.csv')\n",
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
